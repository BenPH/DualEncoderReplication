{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Input, Dense, dot\n",
    "from keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXTERNAL_DATA_DIRECTORY = '../data/external'\n",
    "PROCESSED_DATA_DIRECTORY = '../data/processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding words as GloVe vectors\n",
    "Global Vectors for Word Representation (GloVe) are pre-trained vectors which puts semantically similar words in similar vector space. This set of pre-trained vectors were trained on Common Crawl data. We will embed our words as the GloVe vector if available and a random vector otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH, vocab_index = pickle.load(open(os.path.join(PROCESSED_DATA_DIRECTORY,'params.pkl'), 'rb'))\n",
    "vocab_set = set(vocab_index.keys())\n",
    "num_words = len(vocab_index) + 1\n",
    "embedding_dim = 300 # Length of the Glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building a dictionary of words from our dataset embedded with GloVe vectors\n",
    "embedded_words = {}\n",
    "\n",
    "with open(os.path.join(EXTERNAL_DATA_DIRECTORY, 'glove.840B.300d.txt')) as f:\n",
    "    for line in f:\n",
    "        vals = line.split(' ')\n",
    "        word = vals[0]\n",
    "        if word in vocab_set:\n",
    "            vector = np.asarray(vals[1:], 'float32')\n",
    "            embedded_words[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5723387076426211"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(vocab_index) - len(embedded_words))/len(vocab_index) # proportion of words not found in glove file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building matrix of embedded word vectors. If there is no GloVe representation, the row is random.\n",
    "embeddings_matrix = np.random.uniform(-0.25, 0.25, (num_words, embedding_dim))\n",
    "\n",
    "for word, idx in vocab_index.items():\n",
    "    embedded_word = embedded_words.get(word)\n",
    "    if embedded_word is not None:\n",
    "        embeddings_matrix[idx] = embedded_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "The dual encoder architecture below consists of the context branch and the utterance or response branch. Each branch is a separate recurrent neural network that encodes the embedded text sequences of the context and response.\n",
    "\n",
    "<img src=\"../images/dual_encoder_architecture.png\" alt=\"The dual encoder architecture\" width=\"500\"/>\n",
    "\n",
    "The two encoded vectors are combined as $\\sigma(c^TMr)$ where $c$ and $r$ are the encoded context and response and matrix $M$ is a learned model parameter. <br>\n",
    "Then: $c^TM = r'$ can be thought of as a generated response. $r' \\cdot r$ will yield a similarity vector.\n",
    "And then applying the sigmoid function will return a probability. This is the probability that the response is the correct one to the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "response_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "encoder = Sequential()\n",
    "encoder.add(Embedding(input_dim=num_words,\n",
    "                             output_dim=embedding_dim,\n",
    "                             weights=[embeddings_matrix],\n",
    "                             mask_zero=True))\n",
    "encoder.add(LSTM(200))\n",
    "\n",
    "context_encoded = encoder(context_input)\n",
    "response_encoded = encoder(response_input)\n",
    "\n",
    "generated_response = Dense(200, use_bias=False)(context_encoded) # c*M\n",
    "\n",
    "logits = dot([generated_response, response_encoded], axes=1)\n",
    "\n",
    "probs = Dense(1, activation='sigmoid')(logits)\n",
    "\n",
    "model = Model(inputs=[context_input, response_input], outputs=[probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the processed data\n",
    "\n",
    "Data was filtered and tokenized and saved in pickle files by running: `$ python3 utilities/prepare_data.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_contexts, train_responses, train_labels = pickle.load(\n",
    "                                            open(os.path.join(PROCESSED_DATA_DIRECTORY,'train.pkl'), 'rb'))\n",
    "test_contexts, test_responses, test_labels = pickle.load(\n",
    "                                            open(os.path.join(PROCESSED_DATA_DIRECTORY,'test.pkl'), 'rb'))\n",
    "validation_contexts, validation_responses, validation_labels = pickle.load(\n",
    "                                            open(os.path.join(PROCESSED_DATA_DIRECTORY,'valid.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test and validation sets contain the correct response to a given context as well as 9 false responses. The metric the paper uses is recall at k which is the proportion of test examples that contain the true response in the top $k$ predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall_at_k(predictions, k=1, n=10):\n",
    "    num_examples = float(len(predictions))/n\n",
    "    num_correct = 0\n",
    "    for i in range(0, len(predictions), n):\n",
    "        test_case = predictions[i:i+n]\n",
    "        # 0th example is always the ground truth utterance\n",
    "        if 0 in test_case.argsort(axis=0,)[::-1][:k]:\n",
    "            num_correct += 1\n",
    "    return num_correct/num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "We check the recall at one in 10 each epoch to determine when to stop training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 718540 samples, validate on 130530 samples\n",
      "Epoch 1/1\n",
      "718540/718540 [==============================] - 11092s 15ms/step - loss: 0.5251 - acc: 0.7262 - val_loss: 0.4447 - val_acc: 0.7732\n",
      "0.5225899975839575\n",
      "0.7093500845614883\n",
      "0.9257469598131594\n",
      "Train on 718540 samples, validate on 130530 samples\n",
      "Epoch 1/1\n",
      "718540/718540 [==============================] - 11103s 15ms/step - loss: 0.3995 - acc: 0.8145 - val_loss: 0.4200 - val_acc: 0.7922\n",
      "0.5614882821937666\n",
      "0.7407586373520174\n",
      "0.9331561568816944\n",
      "Train on 718540 samples, validate on 130530 samples\n",
      "Epoch 1/1\n",
      "718540/718540 [==============================] - 11110s 15ms/step - loss: 0.3180 - acc: 0.8590 - val_loss: 0.4705 - val_acc: 0.7817\n",
      "0.5515019731013933\n",
      "0.732463558025288\n",
      "0.9354111299025529\n"
     ]
    }
   ],
   "source": [
    "# Used early stopping if Recall @ 1 decreased\n",
    "old_recall = 0\n",
    "for epoch in range(50):\n",
    "    model.fit([train_contexts, train_responses], train_labels, \n",
    "              validation_data=([validation_contexts, validation_responses], [validation_labels]), \n",
    "              batch_size=256, epochs=1)\n",
    "    \n",
    "    y_pred = model.predict([validation_contexts, validation_responses])\n",
    "    recall_at_one = recall_at_k(y_pred, k=1)\n",
    "    print(recall_at_one, recall_at_k(y_pred, k=2), recall_at_k(y_pred, k=5), sep='\\n')\n",
    "\n",
    "    if recall_at_one <= old_recall:\n",
    "        break\n",
    "    \n",
    "    old_recall = recall_at_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict([test_contexts, test_responses], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall @ 1: 0.5515019731013933\n",
      "recall @ 2: 0.732463558025288\n",
      "recall @ 5: 0.9354111299025529\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 2, 5]:\n",
    "    print(\"recall @ %d in 10:\" % k, recall_at_k(y_pred, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall @ 1 in 2\n",
    "y_pred2 = []\n",
    "for i in range(0, len(y_pred), 10):\n",
    "    y_pred2.append(y_pred[i])\n",
    "    y_pred2.append(y_pred[i+1])\n",
    "y_pred2 = np.array(y_pred2)\n",
    "\n",
    "print(\"recall @ %d in 2:\" % k, recall_at_k(y_pred2, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('dual_encoder_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
